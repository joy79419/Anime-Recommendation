{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "\n",
      "Training recommendation model...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parseline(line):\n",
    "    fields = line.split(',')\n",
    "    userid = fields[0]\n",
    "    username = fields[1]\n",
    "    animeid = fields[2]\n",
    "    score = fields[3]\n",
    "    return (userid, username, animeid, score)\n",
    "\n",
    "def loadUserNames():\n",
    "    usernames = {}\n",
    "    with open(\"animelists_als.csv\", encoding='ascii', errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split(',')\n",
    "            usernames[int(fields[0])] = fields[1]\n",
    "    return usernames\n",
    "\n",
    "nameDict = loadUserNames()\n",
    "    \n",
    "# pyspark set-up\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"AnimeRecommendationsALS\")\n",
    "sc = SparkContext(conf = conf)\n",
    "sc.setCheckpointDir('checkpoint')\n",
    "\n",
    "# Build rating object for ALS \n",
    "print(\"\\nLoading data...\")\n",
    "\n",
    " \n",
    "lines = sc.textFile(\"animelists_als.csv\")\n",
    "parsedlines = lines.map(parseline)\n",
    "ratings = parsedlines.map(lambda l: Rating(int(l[0]), int(l[2]), float(l[3]))).cache()\n",
    "test, train = ratings.randomSplit(weights=[0.2, 0.8], seed=1)\n",
    "testset = test.map(lambda t: (t[0], t[1]))\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "print(\"\\nTraining recommendation model...\")\n",
    "rank = 5\n",
    "numIterations = 20\n",
    "model = ALS.train(train, rank, numIterations)\n",
    "predictions = model.predictAll(testset).collect()\n",
    "embedding = model.userFeatures().collect()\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Output predictions to csv\n",
    "import pandas as pd\n",
    "\n",
    "username = []\n",
    "\n",
    "for userid,itemid,rating in predictions:\n",
    "    username.append(nameDict[userid])\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df['username'] = pd.Series(username)\n",
    "pred_df = pred_df[['user','username', 'product','rating']]\n",
    "#pred_df.to_csv(\"als_predictions.csv\", index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rating = pd.DataFrame(test.collect()).sort_values(by=['user','rating'],ascending=[True,False]).reset_index()['rating']\n",
    "pred_df = pred_df.sort_values(by=['user','rating'],ascending=[True,False]).reset_index()\n",
    "pred_df['true'] = true_rating\n",
    "pred_df = pred_df[['user','product','rating','true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# username = []\n",
    "# for userid, emb in embedding:\n",
    "#     username.append(nameDict[userid])\n",
    "\n",
    "# embedding_df = pd.DataFrame(embedding)\n",
    "# embedding_df['0'], embedding_df['1'], embedding_df['2'], embedding_df['3'], embedding_df['4'] = zip(*embedding_df[1])\n",
    "# embedding_df = embedding_df[[0,'0','1','2','3','4']]\n",
    "# embedding_df['username'] = pd.Series(username)\n",
    "# names = embedding_df.columns.tolist()\n",
    "# names[0] = 'userid'\n",
    "# embedding_df.columns = names\n",
    "# embedding_df = embedding_df[['userid','username','0','1','2','3','4']]\n",
    "# embedding_df.to_csv('als_embedding.csv',header = True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "\n",
    "    ini = defaultdict(list)\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, est in predictions:\n",
    "        ini[uid].append((iid, est))\n",
    "    for uid, iid, true in test.collect():\n",
    "        for i in [x[0] for x in ini[uid]]:\n",
    "            if iid == i:\n",
    "                top_n[uid].append(ini[uid][[x[0] for x in ini[uid]].index(iid)]+(true,))\n",
    "    #uid:[(iid,est),(iid,est)]\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings#[:n]\n",
    "    return top_n\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "users_est = defaultdict(list)\n",
    "users_true=defaultdict(list)\n",
    "for uid, user_ratings in top_n.items():\n",
    "    users_est[uid].append([est for (_, est,_) in user_ratings])\n",
    "    users_true[uid].append([true_r for (_,_,true_r) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, k=None, powered=False):\n",
    "    def dcg(scores, k=None, powered=False):\n",
    "        if k is None:\n",
    "            k = scores.shape[0]\n",
    "        if not powered:\n",
    "            ret = scores[0]\n",
    "            for i in range(1, k):\n",
    "                ret += scores[i] / np.log2(i + 1)\n",
    "            return ret\n",
    "        else:\n",
    "            ret = 0\n",
    "            for i in range(k):\n",
    "                ret += (2 ** scores[i] - 1) / np.log2(i + 2)\n",
    "            return ret\n",
    "    \n",
    "    ideal_sorted_scores = np.sort(y_true)[::-1]\n",
    "    ideal_dcg_score = dcg(ideal_sorted_scores, k=k, powered=powered)\n",
    "    \n",
    "    pred_sorted_ind = np.argsort(y_pred)[::-1]\n",
    "    pred_sorted_scores = y_true[pred_sorted_ind]\n",
    "    dcg_score = dcg(pred_sorted_scores, k=k, powered=powered)\n",
    "    \n",
    "    return dcg_score / ideal_dcg_score\n",
    "\n",
    "def ndcg1(y_true, y_pred, k=None):\n",
    "    return ndcg(y_true, y_pred, k=k, powered=False)\n",
    "\n",
    "def ndcg2(y_true, y_pred, k=None):\n",
    "    return ndcg(y_true, y_pred, k=k, powered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b0130\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG(10) = 0.8616405045908381\n"
     ]
    }
   ],
   "source": [
    "ndcg_list=[]\n",
    "for uid in top_n:\n",
    "    \n",
    "    for i in users_true[uid]:\n",
    "        y_true=np.asarray(i)#.reshape(-1,1)\n",
    "    for i in users_est[uid]:\n",
    "        y_pred=np.asarray(i)#.reshape(-1,1)\n",
    "        ndcg_list.append(ndcg1(y_true, y_pred, k=None))\n",
    "ndcg_list = [i for i in ndcg_list if str(i) != 'nan']\n",
    "print(\"\\nNDCG(10) = %s\" % str(sum(ndcg_list)/len(ndcg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP\n",
    "threshold = 8\n",
    "pred_df['relevant'] = np.where(pred_df['true'] > threshold, 1,0)\n",
    "pred_df['recommended'] = np.where(pred_df['rating'] > threshold, 1,0)\n",
    "def MAP_k(mydf, k=5):\n",
    "   AP = 0.0\n",
    "   for i in mydf['user'].unique():\n",
    "       #print(\"user is\", i)\n",
    "       user_df = mydf[mydf['user'] == i]\n",
    "       user_df.sort_values('rating', axis=0, inplace=True, ascending=False)\n",
    "       top_N_items = user_df['recommended'].values[:k+1]\n",
    "       #print(\"top items\", top_N_items )\n",
    "       p_list = np.empty((0,k), int)\n",
    "       for j in range(len(top_N_items)):\n",
    "           l = user_df['recommended'].values[:j+1]\n",
    "           val = np.sum(l)/len(l)\n",
    "           p_list = np.append(p_list, val)\n",
    "       #print(\"List is\",p_list)\n",
    "       sum_val = sum(p_list * top_N_items)\n",
    "       if(sum(user_df['relevant'] >0)):\n",
    "           AP = AP + sum_val/sum(user_df['relevant'])\n",
    "   MAP = AP/mydf['user'].nunique()\n",
    "   return MAP\n",
    "\n",
    "MAP_k(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Test RMSE...\n",
      "\n",
      "Test RMSE = 3.059517496275762\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating Test RMSE...\")\n",
    "testData = test.map(lambda p: (p.user, p.product))\n",
    "predictions = model.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))\n",
    "ratingsTuple = test.map(lambda r: ((r.user, r.product), r.rating))\n",
    "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])\n",
    "\n",
    "metrics_rating = RegressionMetrics(scoreAndLabels)\n",
    "print(\"\\nTest RMSE = %s\" % metrics_rating.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
